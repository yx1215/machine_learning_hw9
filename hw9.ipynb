{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5d3e34be-95f4-4e5f-b5b3-80ce75d8a428",
    "_uuid": "a3e6a588780b2161ddd38479bac77164d99cd00b"
   },
   "source": [
    "# 1. Convolutional Neural Networks Visualization in Pytorch\n",
    "\n",
    "In this kernel, we'll look into a convolutional network, to try and understand how they work by generating images that maximize the activation of the filters in the convolutional layers.\n",
    "To generate these images, we apply gradient ascent to the inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "cf1d4afa-28c8-4e95-be07-5d13211192e9",
    "_uuid": "a8d45e892df93c2ba4f1a11a8cc4fa7a63c7ac5e"
   },
   "source": [
    "## Packages and utils functions\n",
    "\n",
    "Some util functions to load and visualize images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d8437be7-1af2-4056-9c57-1c751ec71b79",
    "_uuid": "04ea043d76780d5dd39f8d6673b9d6b850b8bdff",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "6uznQ7thrODO"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import SGD\n",
    "from torchvision import models, transforms\n",
    "import PIL\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "import scipy.ndimage as ndimage\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import scipy.ndimage as nd\n",
    "import PIL.Image\n",
    "from IPython.display import clear_output, Image, display\n",
    "from io import BytesIO\n",
    "\n",
    "\n",
    "def showarray(a, fmt='jpeg'):\n",
    "    a = np.uint8(np.clip(a, 0, 255))\n",
    "    f = BytesIO()\n",
    "    PIL.Image.fromarray(a).save(f, fmt)\n",
    "    display(Image(data=f.getvalue()))\n",
    "    \n",
    "def showtensor(a):\n",
    "    mean = np.array([0.485, 0.456, 0.406]).reshape([1, 1, 3])\n",
    "    std = np.array([0.229, 0.224, 0.225]).reshape([1, 1, 3])\n",
    "    inp = a[0, :, :, :]\n",
    "    inp = inp.transpose(1, 2, 0)\n",
    "    inp = std * inp + mean\n",
    "    inp *= 255\n",
    "    showarray(inp)\n",
    "    clear_output(wait=True)\n",
    "\n",
    "def plot_images(im, titles=None):\n",
    "    plt.figure(figsize=(30, 20))\n",
    "    \n",
    "    for i in range(len(im)):\n",
    "        plt.subplot(10 / 5 + 1, 5, i + 1)\n",
    "        plt.axis('off')\n",
    "        if titles is not None:\n",
    "            plt.title(titles[i])\n",
    "        plt.imshow(im[i])\n",
    "        \n",
    "    plt.pause(0.001)\n",
    "    \n",
    "normalise = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "normalise_resize = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def init_image(size=(400, 400, 3)):\n",
    "    img = PIL.Image.fromarray(np.uint8(np.full(size, 150)))\n",
    "    img = PIL.Image.fromarray(np.uint8(np.random.uniform(150, 180, size)))\n",
    "    img_tensor = normalise(img).unsqueeze(0)\n",
    "    img_np = img_tensor.numpy()\n",
    "    return img, img_tensor, img_np\n",
    "\n",
    "def load_image(path, resize=False, size=None):\n",
    "    img = PIL.Image.open(path)\n",
    "    \n",
    "    if size is not None:\n",
    "        img.thumbnail(size, PIL.Image.ANTIALIAS)\n",
    "        \n",
    "    if resize:\n",
    "        img_tensor = normalise_resize(img).unsqueeze(0)\n",
    "    else:\n",
    "        img_tensor = normalise(img).unsqueeze(0)\n",
    "    img_np = img_tensor.numpy()\n",
    "    return img, img_tensor, img_np\n",
    "\n",
    "def tensor_to_img(t):\n",
    "    a = t.numpy()\n",
    "    mean = np.array([0.485, 0.456, 0.406]).reshape([1, 1, 3])\n",
    "    std = np.array([0.229, 0.224, 0.225]).reshape([1, 1, 3])\n",
    "    inp = a[0, :, :, :]\n",
    "    inp = inp.transpose(1, 2, 0)\n",
    "    inp = std * inp + mean\n",
    "    inp *= 255\n",
    "    inp = np.uint8(np.clip(inp, 0, 255))\n",
    "    return PIL.Image.fromarray(inp)\n",
    "\n",
    "def image_to_variable(image, requires_grad=False, cuda=False):\n",
    "    if cuda:\n",
    "        image = Variable(image.cuda(), requires_grad=requires_grad)\n",
    "    else:\n",
    "        image = Variable(image, requires_grad=requires_grad)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "81f70ff4-8df4-49b3-affa-35d7258b9238",
    "_uuid": "ec5ad7387662324efc96241675dced3c1e1efd3d"
   },
   "source": [
    "## Model Creation\n",
    "\n",
    "Here we load a pretrained VGG-16 model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "85f7db57-66a7-46d9-a30c-cf13d44d55a0",
    "_uuid": "9f941397cbeaf6a6da3b7b2f7c52817909cb87f7",
    "colab_type": "text",
    "id": "i1gG6SapzgKD"
   },
   "source": [
    "## Filter Visualization\n",
    "\n",
    "This function produces an image that maximizes the activation of the filter at *filter_index* in the layer *layer_index*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually when we train a Neural Net(NN), we use the following steps.\n",
    "```\n",
    "while not converge:\n",
    "    take some inputs\n",
    "    calucate predictions\n",
    "    compute loss\n",
    "    Do gradient descent on loss to update the weights in each layer\n",
    "```\n",
    "This procedure is shown in the following picture.\n",
    "![](./pictures/nn_train.png)\n",
    "After training a model, one interesting thing we want to do is that we would like to know what excatly each neuron in different layers look like. One way to do that is we start with inputting a picture with random pixels to the NN, and calculate the activations for the neuron that you want to visualize. Note that larger activations mean that the picture contains features that are closer to what is represented by this neuron, thus we want to maximize the activation. So after calculating the activation, we will do gradient ascent on the activation to update the input image.(All the gradients here are taken with respect to inputs, i.e. each pixel's value).\n",
    "\n",
    "These are the steps described above.\n",
    "```\n",
    "intialize a random picture A\n",
    "while not converge:\n",
    "    Input A to the NN\n",
    "    calucate activation for the specific neuron that you want to visualize\n",
    "    Do gradient ascent on activation to update A\n",
    "```\n",
    "This procedure is shown in the following picture.\n",
    "![](./pictures/filter_visualization.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our exercise, we will use a pretrained model in pytorch called [VGG](https://arxiv.org/abs/1409.1556). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "cea19113-e7c9-47a7-ab1d-b9178ef990b1",
    "_uuid": "f972135ef1068a6ef3b644d15459159ee0dbacb7",
    "colab_type": "text",
    "id": "7Vl6h9rjzgJ-"
   },
   "source": [
    "## Octaver function\n",
    "\n",
    "The octaver function is used to produce better output images. This procedure is taken from the [Deep Dream code](https://github.com/google/deepdream/blob/master/dream.ipynb). \n",
    "We will use it not only for the deep dream algorithm, but also for visualizing the filters.\n",
    "The gradient ascent algorithm is run on multiple downscaled versions of the image, and the results are upscaled and merged together to get the final image.\n",
    "\n",
    "![](https://raw.githubusercontent.com/Hvass-Labs/TensorFlow-Tutorials/master/images/14_deepdream_recursive_flowchart.png)\n",
    "*Figure 1: Flowchart of the octaver function + deep dream, taken from https://github.com/Hvass-Labs/TensorFlow-Tutorials*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "271c55bc-ca04-4b81-90ef-8d34fc7fc4d9",
    "_uuid": "89b7471b46c7ca2c71ca61ef7d4951eed0f7311f",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "RhQv-47lrODU"
   },
   "outputs": [],
   "source": [
    "model = models.vgg16()\n",
    "model.load_state_dict(torch.load(\"./input/vgg16/vgg16.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c734253c-7d4d-4afb-bfef-685cac98288e",
    "_uuid": "f62aa020ad0899460defa9e49be8d9f89c531a67",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 765
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2770,
     "status": "ok",
     "timestamp": 1526052553869,
     "user": {
      "displayName": "Carlo Alberto",
      "photoUrl": "//lh5.googleusercontent.com/-_sBZsyc315U/AAAAAAAAAAI/AAAAAAAAAgg/b4D9SE9jgD0/s50-c-k-no/photo.jpg",
      "userId": "107843268563316278814"
     },
     "user_tz": -120
    },
    "id": "4aRAE7SqzPCK",
    "outputId": "f10a5dda-457b-4989-a801-d4ba16a3355c"
   },
   "outputs": [],
   "source": [
    "use_gpu = False\n",
    "if torch.cuda.is_available():\n",
    "    use_gpu = True\n",
    "\n",
    "print(model)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Octaver Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG model was trained on images of fairly low resolution, 224 * 224 pixels. So when we use images with much larger resolution, the algorithm described will create many small patterns instead of big ones. \n",
    "\n",
    "One solution is to downscale the input image to the same size. But such a low resolution is pixelated and ugly. \n",
    "\n",
    "Another solution is to repeatedly downscale the original image and run the algorithm on each of the smaller versions of the image. This creates larger patterns in the \n",
    "image that are then refined at the higher resolution. \n",
    "\n",
    "This flowchart shows roughly the idea. The algorithm is implemented recursively and supports any number of downscaling levels. \n",
    "![](./pictures/octaver_fn.png)\n",
    "\n",
    "The function ```octaver_fn()``` implements what is described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "fe851140-9d40-47ea-be78-517bc4a2238a",
    "_uuid": "1ef4e55fd8179faa8f2ee35016cae9c8b1e1e113",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "dxd0ATHnzgJ_"
   },
   "outputs": [],
   "source": [
    "# Finish this function\n",
    "def octaver_fn(model, base_img, step_fn, octave_n=6, octave_scale=1.4, iter_n=10, **step_args):\n",
    "    octaves = [base_img]\n",
    "    # model: pretrained model\n",
    "    # base_image: the image that you want to modify\n",
    "    # step_fn: function for doing a single gradient ascent step\n",
    "    # octave_n: how many times you want to zoom your picture\n",
    "    # octave_scale: how much you want to zoom your picture each time\n",
    "    # iter_n: num of gradient ascent steps you want to take \n",
    "    # step_args: a dictionary containing all the kwargs for step_fn\n",
    "    for i in range(octave_n - 1):\n",
    "        octaves.append(nd.zoom(octaves[-1], (1, 1, 1.0 / octave_scale, 1.0 / octave_scale), order=1))\n",
    "\n",
    "    detail = np.zeros_like(octaves[-1])\n",
    "    for octave, octave_base in enumerate(octaves[::-1]):\n",
    "        h, w = octave_base.shape[-2:]\n",
    "        \n",
    "        if octave > 0:\n",
    "            h1, w1 = detail.shape[-2:]\n",
    "            detail = nd.zoom(detail, (1, 1, 1.0 * h / h1, 1.0 * w / w1), order=1)\n",
    "        \n",
    "        src = octave_base + detail\n",
    "        \n",
    "        for i in range(iter_n):\n",
    "            src = ...\n",
    "\n",
    "        detail = src.numpy() - octave_base\n",
    "\n",
    "    return src"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function ```filter_step()``` implements one single gradient ascent step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "27c0ae4b-d6e5-430c-86dc-930110822bbd",
    "_uuid": "0e6bb7328fa31ac1a174fd8101411d7c90fc7ba6",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Sx1jZfDJzgKE"
   },
   "outputs": [],
   "source": [
    "def filter_step(model, img, layer_index, filter_index, step_size=0.05, display=True, use_L2=False):\n",
    "    \n",
    "    mean = np.array([0.485, 0.456, 0.406]).reshape([3, 1, 1])\n",
    "    std = np.array([0.229, 0.224, 0.225]).reshape([3, 1, 1])\n",
    "    \n",
    "    model.zero_grad()\n",
    "    \n",
    "    img_var = image_to_variable(torch.Tensor(img), requires_grad=True, cuda=use_gpu)\n",
    "    optimizer = SGD([img_var], lr=step_size, weight_decay=1e-4)\n",
    "    \n",
    "    x = img_var\n",
    "    for index, layer in enumerate(model.features):\n",
    "        ...\n",
    "\n",
    "    output = x[0, filter_index]\n",
    "    loss = output.norm()\n",
    "    loss.backward()\n",
    "    \n",
    "    if use_L2:\n",
    "        #L2 normalization on gradients\n",
    "        mean_square = torch.Tensor([torch.mean(img_var.grad.data ** 2) + 1e-5])\n",
    "        img_var.grad.data /= torch.sqrt(mean_square)\n",
    "        img_var.data.add_(img_var.grad.data * step_size)\n",
    "    else:\n",
    "        optimizer.step()\n",
    "    \n",
    "    result = img_var.data.cpu().numpy()\n",
    "    result[0, :, :, :] = np.clip(result[0, :, :, :], -mean / std, (1 - mean) / std)\n",
    "    \n",
    "    if display:\n",
    "        showtensor(result)\n",
    "    \n",
    "    return torch.Tensor(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function ```visualize_filter()``` visualize one single filter using ```octaver_fun()```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_filter(model, base_img, layer_index, filter_index, \n",
    "                     octave_n=6, octave_scale=1.4, iter_n=10, \n",
    "                     step_size=0.05, display=True, use_L2=False):\n",
    "    \n",
    "    return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "88f89e41-5fcc-437a-90b5-8e3c472b1740",
    "_uuid": "571146fbd4f5a44dd81f1fb5ea97918800966e49"
   },
   "source": [
    "The function ```show_layer()``` is a helper function to visualize a number of filters for a given layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ddd34a1c-1e38-4f62-90e2-1e327ba20e5a",
    "_uuid": "aa0a667e95b0a82666aaaab97064074d05d66d73",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "teKi_nzKzgKH"
   },
   "outputs": [],
   "source": [
    "def show_layer(layer_num, filter_start=10, filter_end=20, step_size=0.05, use_L2=False):\n",
    "    filters = []\n",
    "    titles = []\n",
    "    \n",
    "    _, _, img_np = init_image(size=(600, 600, 3))\n",
    "    for i in range(filter_start, filter_end):\n",
    "        title = \"Layer {} Filter {}\".format(layer_num , i)\n",
    "        print(title)\n",
    "        filter = ...\n",
    "        filter_img = tensor_to_img(filter)\n",
    "#         filter_img.save(title + \".jpg\")\n",
    "        filters.append(tensor_to_img(filter))\n",
    "        titles.append(title)\n",
    "        \n",
    "    \n",
    "    plot_images(filters, titles)\n",
    "    return filters, titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have finished all the functions you need to visualize some filters. Your task here is to use the functions above to visualize some filters in some layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, visualize filter 11 to 15 in layer 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3106447b-883d-4664-a765-ab195936d588",
    "_uuid": "282422e5ccc9f792c20b82208f26cbcee89ad834"
   },
   "outputs": [],
   "source": [
    "images, titles = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, visualize filter 11 to 15 in layer 10 (This might take some time to run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8eaa0496-dbf4-4f88-bcf4-697afd22b4c5",
    "_uuid": "7d000e5c39593adfe4be64e8751d8ccbb14e5c4b",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 735
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 379,
     "status": "ok",
     "timestamp": 1526052782636,
     "user": {
      "displayName": "Carlo Alberto",
      "photoUrl": "//lh5.googleusercontent.com/-_sBZsyc315U/AAAAAAAAAAI/AAAAAAAAAgg/b4D9SE9jgD0/s50-c-k-no/photo.jpg",
      "userId": "107843268563316278814"
     },
     "user_tz": -120
    },
    "id": "hMjh0FtozgKL",
    "outputId": "9c9421a6-230c-4af5-df1c-2a76683fa6c4"
   },
   "outputs": [],
   "source": [
    "images, titles = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: Compare your visualizations for layer 1 and layer 10, what's the difference in the patterns shown?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5956e8f6-e91e-4595-9e7f-c43fc0941574",
    "_uuid": "a841351ff9958c3d0533334b0a5025940d894a3b",
    "colab_type": "text",
    "id": "jqTQYKbNzQgc"
   },
   "source": [
    "## Deep Dream\n",
    "\n",
    "The Deep Dream function is similar to the filter visualization, but instead of starting from a random noise image, we start from an actual picture and try to maximize the network output. In this way, we're enhancing the features that the network recognizes in the image. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function ```make_step``` implements one single gradient ascent step for deap dream algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c99d972d-b603-48f8-b3fb-500ba56cdba9",
    "_uuid": "d1eaf9df9e44130031b6ce04eb495ac8275e1818",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "GN5b7hTJzQgd",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def objective(dst, guide_features):\n",
    "    if guide_features is None:\n",
    "        return dst.data\n",
    "    else:\n",
    "        x = dst.data[0].cpu().numpy()\n",
    "        y = guide_features.data[0].cpu().numpy()\n",
    "        ch, w, h = x.shape\n",
    "        x = x.reshape(ch, -1)\n",
    "        y = y.reshape(ch, -1)\n",
    "        A = x.T.dot(y)\n",
    "        diff = y[:, A.argmax(1)]\n",
    "        diff = torch.Tensor(np.array([diff.reshape(ch, w, h)]))\n",
    "        return diff\n",
    "\n",
    "def make_step(model, img, objective=objective, control=None, step_size=1.5, end=28, jitter=32):\n",
    "    mean = np.array([0.485, 0.456, 0.406]).reshape([3, 1, 1])\n",
    "    std = np.array([0.229, 0.224, 0.225]).reshape([3, 1, 1])\n",
    "    \n",
    "    ox, oy = np.random.randint(-jitter, jitter+1, 2)\n",
    "    \n",
    "    img = np.roll(np.roll(img, ox, -1), oy, -2)\n",
    "    tensor = torch.Tensor(img) \n",
    "    \n",
    "    img_var = image_to_variable(tensor, requires_grad=True, cuda=use_gpu)\n",
    "    model.zero_grad()\n",
    "      \n",
    "    x = img_var\n",
    "    for index, layer in enumerate(model.features.children()):\n",
    "        ...\n",
    "    \n",
    "    delta = objective(x, control)\n",
    "    x.backward(delta)\n",
    "    \n",
    "    #L2 Regularization on gradients\n",
    "    mean_square = torch.Tensor([torch.mean(img_var.grad.data ** 2)])\n",
    "    img_var.grad.data /= torch.sqrt(mean_square)\n",
    "    img_var.data.add_(img_var.grad.data * step_size)\n",
    "    \n",
    "    result = img_var.data.cpu().numpy()\n",
    "    result = np.roll(np.roll(result, -ox, -1), -oy, -2)\n",
    "    result[0, :, :, :] = np.clip(result[0, :, :, :], -mean / std, (1 - mean) / std)\n",
    "    showtensor(result)\n",
    "    \n",
    "    return torch.Tensor(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function ```deepdream()``` is a wrapper function using the implemented ```octaver_fn()``` on the above step function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepdream(model, base_img, octave_n=6, octave_scale=1.4, \n",
    "              iter_n=10, end=28, control=None, objective=objective, \n",
    "              step_size=1.5, jitter=32):\n",
    "    \n",
    "    return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's select a pciture and show it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "149ca97f-00b7-43c3-a8e0-871f8efe77d3",
    "_uuid": "863fb94188c95aef2aa6f3bbb786f697eab8ed43",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 747
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4410,
     "status": "ok",
     "timestamp": 1526053309796,
     "user": {
      "displayName": "Carlo Alberto",
      "photoUrl": "//lh5.googleusercontent.com/-_sBZsyc315U/AAAAAAAAAAI/AAAAAAAAAgg/b4D9SE9jgD0/s50-c-k-no/photo.jpg",
      "userId": "107843268563316278814"
     },
     "user_tz": -120
    },
    "id": "XZB9hS2zyVLt",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "bd9f48b8-c66a-43fc-a987-f7d31920af0b"
   },
   "outputs": [],
   "source": [
    "input_img, input_tensor, input_np = load_image('./input/data/market1.jpg', size=[1024, 1024])\n",
    "print(input_img.size)\n",
    "input_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we apply the deepdream function on layer 14 on it to see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d045dbee-8cba-47f6-9ff6-c8e40a3d3667",
    "_uuid": "a4247b2ceb5987ee6532a8681b38a28708125102",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 730
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1526053406741,
     "user": {
      "displayName": "Carlo Alberto",
      "photoUrl": "//lh5.googleusercontent.com/-_sBZsyc315U/AAAAAAAAAAI/AAAAAAAAAgg/b4D9SE9jgD0/s50-c-k-no/photo.jpg",
      "userId": "107843268563316278814"
     },
     "user_tz": -120
    },
    "id": "pwPcM7iIyrbV",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "4b8a8981-85cd-4632-9224-6456ea2c2854"
   },
   "outputs": [],
   "source": [
    "dream = ...\n",
    "dream = tensor_to_img(dream)\n",
    "dream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ae39a43c-ff5c-4b17-b29e-3be651da2204",
    "_uuid": "0dd0c071e08f2d0378b2ae6e85763948fe27494a"
   },
   "source": [
    "## Controlling the dream\n",
    "\n",
    "We can control the dream by trying to alter the image in order to maximize the filters that are activated by another image (which we'll call guide). The idea would be we input the guide image into the NN and stops at the layer that you want to do deepdream on. The values you got are called guide features. Then when you input your picture which you want to do deepdream on, you would like to make the result on your chosen layer as close to the guide features as possible. (Actually this process has been implemented already, you just need to find out how to use it.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7fc0ddc6-9caa-40da-a6ac-382046d27ebd",
    "_uuid": "588da3147d76131c49213113be27ee6b8fc44b3c",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1017,
     "status": "ok",
     "timestamp": 1526054100646,
     "user": {
      "displayName": "Carlo Alberto",
      "photoUrl": "//lh5.googleusercontent.com/-_sBZsyc315U/AAAAAAAAAAI/AAAAAAAAAgg/b4D9SE9jgD0/s50-c-k-no/photo.jpg",
      "userId": "107843268563316278814"
     },
     "user_tz": -120
    },
    "id": "S97NHU7sY8Yf",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "7a169f5b-1d77-4de3-b837-c8e4e29abfa0"
   },
   "outputs": [],
   "source": [
    "guide_img, guide_img_tensor, guide_img_np = load_image('./input/data/kitten2.jpg', resize=True)\n",
    "plt.imshow(guide_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2fe6d591-8926-4f48-b4a9-d2ead3081649",
    "_uuid": "a2cabeef0eb4ef98b9fa1a3c982833065429bb2d",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 730
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1526054232473,
     "user": {
      "displayName": "Carlo Alberto",
      "photoUrl": "//lh5.googleusercontent.com/-_sBZsyc315U/AAAAAAAAAAI/AAAAAAAAAgg/b4D9SE9jgD0/s50-c-k-no/photo.jpg",
      "userId": "107843268563316278814"
     },
     "user_tz": -120
    },
    "id": "tSJ3RNxaZlkH",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "4ebbbf4a-4bef-45a5-ed55-14aa40435172"
   },
   "outputs": [],
   "source": [
    "end = 26\n",
    "\n",
    "guide_image = image_to_variable(guide_img_tensor, cuda=use_gpu)\n",
    "\n",
    "# genrate guide features by input the guide image into the NN until the wanted layer.\n",
    "...\n",
    "    \n",
    "dream = deepdream(model, input_np, end=end, step_size=0.06, octave_n=4, control=guide_features)\n",
    "dream = tensor_to_img(dream)\n",
    "dream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are other pictures provided in the homework zip, you can try them if you want!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Feature selection using RF, PCA and Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are reusing the dataset from hw6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./datasets/VideoGameSales.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"Name\", axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df[[\"Global_Sales\"]].values.ravel()\n",
    "\n",
    "# Generate dummies for all catagrical features\n",
    "X = pd.get_dummies(df.drop([\"Global_Sales\"], axis=1)).values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0, shuffle=False)\n",
    "\n",
    "\n",
    "print(\"Original:\", X.shape)\n",
    "print(\"Train:   \", X_train.shape,y_train.shape)\n",
    "print(\"Test:    \", X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section you need to do the following:\n",
    " - Fit a PCA with 10 components\n",
    " - Draw a plot showing the explained variance ratio for each principle compoenent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: How would you determine the number of principle components to use?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section you need to do the following:\n",
    " - Fit a Random Forest\n",
    " - Draw a barchart showing the feature importance from RF for each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: According to feature importance, how would you select your features?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section you need to do the following:\n",
    " - Fit a Lasso with alpha=0.1\n",
    " - Draw a barchart showing the weights for each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: According to Lasso, what are the features that need to be deleted? Comparing with RF, do the selected features match?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "CNN Visualization.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
